{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1 – Training data\n",
    "train = [(\"Great place to be when you are in Bangalore.\", \"pos\"),\n",
    "  (\"The place was being renovated when I visited so the seating was limited.\", \"neg\"),\n",
    "  (\"Loved the ambience, loved the food\", \"pos\"),\n",
    "  (\"The food is delicious but not over the top.\", \"neg\"),\n",
    "  (\"Service - Little slow, probably because too many people.\", \"neg\"),\n",
    "  (\"The place is not easy to locate\", \"neg\"),\n",
    "  (\"Mushroom fried rice was spicy\", \"pos\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Great place to be when you are in Bangalore.', 'pos'), ('The place was being renovated when I visited so the seating was limited.', 'neg'), ('Loved the ambience, loved the food', 'pos'), ('The food is delicious but not over the top.', 'neg'), ('Service - Little slow, probably because too many people.', 'neg'), ('The place is not easy to locate', 'neg'), ('Mushroom fried rice was spicy', 'pos')]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-', 'because', 'to', 'fried', 'limited', 'is', 'are', ',', 'easy', 'service', 'i', 'too', 'was', 'food', 'people', 'when', 'mushroom', '.', 'over', 'loved', 'not', 'renovated', 'be', 'being', 'rice', 'in', 'probably', 'top', 'place', 'little', 'great', 'so', 'seating', 'bangalore', 'ambience', 'slow', 'locate', 'the', 'spicy', 'you', 'visited', 'many', 'but', 'delicious'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2\n",
    "dictionary = set(word.lower() for doc in train for word in word_tokenize(doc[0]))\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'-': False, 'because': False, 'to': True, 'fried': False, 'limited': False, 'is': False, 'are': True, ',': False, 'easy': False, 'service': False, 'i': False, 'too': False, 'was': False, 'food': False, 'people': False, 'when': True, 'mushroom': False, '.': True, 'over': False, 'loved': False, 'not': False, 'renovated': False, 'be': True, 'being': False, 'rice': False, 'in': True, 'probably': False, 'top': False, 'place': True, 'little': False, 'great': False, 'so': False, 'seating': False, 'bangalore': False, 'ambience': False, 'slow': False, 'locate': False, 'the': False, 'spicy': False, 'you': True, 'visited': False, 'many': False, 'but': False, 'delicious': False}, 'pos'), ({'-': False, 'because': False, 'to': False, 'fried': False, 'limited': True, 'is': False, 'are': False, ',': False, 'easy': False, 'service': False, 'i': False, 'too': False, 'was': True, 'food': False, 'people': False, 'when': True, 'mushroom': False, '.': True, 'over': False, 'loved': False, 'not': False, 'renovated': True, 'be': False, 'being': True, 'rice': False, 'in': False, 'probably': False, 'top': False, 'place': True, 'little': False, 'great': False, 'so': True, 'seating': True, 'bangalore': False, 'ambience': False, 'slow': False, 'locate': False, 'the': True, 'spicy': False, 'you': False, 'visited': True, 'many': False, 'but': False, 'delicious': False}, 'neg'), ({'-': False, 'because': False, 'to': False, 'fried': False, 'limited': False, 'is': False, 'are': False, ',': True, 'easy': False, 'service': False, 'i': False, 'too': False, 'was': False, 'food': True, 'people': False, 'when': False, 'mushroom': False, '.': False, 'over': False, 'loved': True, 'not': False, 'renovated': False, 'be': False, 'being': False, 'rice': False, 'in': False, 'probably': False, 'top': False, 'place': False, 'little': False, 'great': False, 'so': False, 'seating': False, 'bangalore': False, 'ambience': True, 'slow': False, 'locate': False, 'the': True, 'spicy': False, 'you': False, 'visited': False, 'many': False, 'but': False, 'delicious': False}, 'pos'), ({'-': False, 'because': False, 'to': False, 'fried': False, 'limited': False, 'is': True, 'are': False, ',': False, 'easy': False, 'service': False, 'i': False, 'too': False, 'was': False, 'food': True, 'people': False, 'when': False, 'mushroom': False, '.': True, 'over': True, 'loved': False, 'not': True, 'renovated': False, 'be': False, 'being': False, 'rice': False, 'in': False, 'probably': False, 'top': True, 'place': False, 'little': False, 'great': False, 'so': False, 'seating': False, 'bangalore': False, 'ambience': False, 'slow': False, 'locate': False, 'the': True, 'spicy': False, 'you': False, 'visited': False, 'many': False, 'but': True, 'delicious': True}, 'neg'), ({'-': True, 'because': True, 'to': False, 'fried': False, 'limited': False, 'is': False, 'are': False, ',': True, 'easy': False, 'service': False, 'i': False, 'too': True, 'was': False, 'food': False, 'people': True, 'when': False, 'mushroom': False, '.': True, 'over': False, 'loved': False, 'not': False, 'renovated': False, 'be': False, 'being': False, 'rice': False, 'in': False, 'probably': True, 'top': False, 'place': False, 'little': False, 'great': False, 'so': False, 'seating': False, 'bangalore': False, 'ambience': False, 'slow': True, 'locate': False, 'the': False, 'spicy': False, 'you': False, 'visited': False, 'many': True, 'but': False, 'delicious': False}, 'neg'), ({'-': False, 'because': False, 'to': True, 'fried': False, 'limited': False, 'is': True, 'are': False, ',': False, 'easy': True, 'service': False, 'i': False, 'too': False, 'was': False, 'food': False, 'people': False, 'when': False, 'mushroom': False, '.': False, 'over': False, 'loved': False, 'not': True, 'renovated': False, 'be': False, 'being': False, 'rice': False, 'in': False, 'probably': False, 'top': False, 'place': True, 'little': False, 'great': False, 'so': False, 'seating': False, 'bangalore': False, 'ambience': False, 'slow': False, 'locate': True, 'the': False, 'spicy': False, 'you': False, 'visited': False, 'many': False, 'but': False, 'delicious': False}, 'neg'), ({'-': False, 'because': False, 'to': False, 'fried': True, 'limited': False, 'is': False, 'are': False, ',': False, 'easy': False, 'service': False, 'i': False, 'too': False, 'was': True, 'food': False, 'people': False, 'when': False, 'mushroom': False, '.': False, 'over': False, 'loved': False, 'not': False, 'renovated': False, 'be': False, 'being': False, 'rice': True, 'in': False, 'probably': False, 'top': False, 'place': False, 'little': False, 'great': False, 'so': False, 'seating': False, 'bangalore': False, 'ambience': False, 'slow': False, 'locate': False, 'the': False, 'spicy': True, 'you': False, 'visited': False, 'many': False, 'but': False, 'delicious': False}, 'pos')]\n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "t = [({word: (word in word_tokenize(x[0])) for word in dictionary}, x[1]) for x in train]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4 – the classifier is trained with sample data\n",
    "classifier = nltk.NaiveBayesClassifier.train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "test_data = \"Manchurian was hot and spicy\"\n",
    "test_data_features = {word.lower(): (word in word_tokenize(test_data.lower())) for word in dictionary}\n",
    "  \n",
    "print (classifier.classify(test_data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative,Not Available\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analyze the tweets for sentiment\n",
    "file = open(\"E:\\\\tweetsentiments.csv\")\n",
    "raw_data = file.readlines()\n",
    "raw_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Not Available', 'negative'],\n",
       " ['IOS 9 App Transport Security. Mm need to check if my 3rd party network pod supports it http://t.co/fmtcfUAdgj',\n",
       "  'neutral'],\n",
       " ['\"Mar if you have an iOS device', 'neutral'],\n",
       " ['@jimmie_vanagon my phone does not run on latest IOS which may account for problem the other day .. time it was replaced',\n",
       "  'negative']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "for row in raw_data:\n",
    "#for row in raw_data[1:5]:\n",
    "    new_row = []\n",
    "    new_row.append(row.split(\",\")[1].rstrip(\"\\n\") )\n",
    "    new_row.append(row.split(\",\")[0])\n",
    "    train.append(new_row)\n",
    "#print(train)\n",
    "train_sample = train[1:5]\n",
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'party', 'available', 'transport', 'to', '``', '3rd', 'mar', 'device', 'jimmie_vanagon', 'problem', 'replaced', 'security', 'check', 'pod', '9', ':', 'run', 'may', 'app', 'other', 'account', 'was', 'it', 'an', '.', 'ios', 'phone', 'if', 'not', 'latest', 'time', 'http', 'on', 'mm', 'does', '@', 'network', 'supports', 'for', '..', '//t.co/fmtcfuadgj', 'which', 'the', 'you', 'my', 'need', 'day', 'have'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2\n",
    "dictionary = set(word.lower() for doc in train_sample for word in word_tokenize(doc[0]))\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'party': False, 'available': False, 'transport': False, 'to': False, '``': False, '3rd': False, 'mar': False, 'device': False, 'jimmie_vanagon': False, 'problem': False, 'replaced': False, 'security': False, 'check': False, 'pod': False, '9': False, ':': False, 'run': False, 'may': False, 'app': False, 'other': False, 'account': False, 'was': False, 'it': False, 'an': False, '.': False, 'ios': False, 'phone': False, 'if': False, 'not': False, 'latest': False, 'time': False, 'http': False, 'on': False, 'mm': False, 'does': False, '@': False, 'network': False, 'supports': False, 'for': False, '..': False, '//t.co/fmtcfuadgj': False, 'which': False, 'the': False, 'you': False, 'my': False, 'need': False, 'day': False, 'have': False}, 'negative'), ({'party': True, 'available': False, 'transport': False, 'to': True, '``': False, '3rd': True, 'mar': False, 'device': False, 'jimmie_vanagon': False, 'problem': False, 'replaced': False, 'security': False, 'check': True, 'pod': True, '9': True, ':': True, 'run': False, 'may': False, 'app': False, 'other': False, 'account': False, 'was': False, 'it': True, 'an': False, '.': True, 'ios': False, 'phone': False, 'if': True, 'not': False, 'latest': False, 'time': False, 'http': True, 'on': False, 'mm': False, 'does': False, '@': False, 'network': True, 'supports': True, 'for': False, '..': False, '//t.co/fmtcfuadgj': False, 'which': False, 'the': False, 'you': False, 'my': True, 'need': True, 'day': False, 'have': False}, 'neutral'), ({'party': False, 'available': False, 'transport': False, 'to': False, '``': True, '3rd': False, 'mar': False, 'device': True, 'jimmie_vanagon': False, 'problem': False, 'replaced': False, 'security': False, 'check': False, 'pod': False, '9': False, ':': False, 'run': False, 'may': False, 'app': False, 'other': False, 'account': False, 'was': False, 'it': False, 'an': True, '.': False, 'ios': False, 'phone': False, 'if': True, 'not': False, 'latest': False, 'time': False, 'http': False, 'on': False, 'mm': False, 'does': False, '@': False, 'network': False, 'supports': False, 'for': False, '..': False, '//t.co/fmtcfuadgj': False, 'which': False, 'the': False, 'you': True, 'my': False, 'need': False, 'day': False, 'have': True}, 'neutral'), ({'party': False, 'available': False, 'transport': False, 'to': False, '``': False, '3rd': False, 'mar': False, 'device': False, 'jimmie_vanagon': True, 'problem': True, 'replaced': True, 'security': False, 'check': False, 'pod': False, '9': False, ':': False, 'run': True, 'may': True, 'app': False, 'other': True, 'account': True, 'was': True, 'it': True, 'an': False, '.': False, 'ios': False, 'phone': True, 'if': False, 'not': True, 'latest': True, 'time': True, 'http': False, 'on': True, 'mm': False, 'does': True, '@': True, 'network': False, 'supports': False, 'for': True, '..': True, '//t.co/fmtcfuadgj': False, 'which': True, 'the': True, 'you': False, 'my': True, 'need': False, 'day': True, 'have': False}, 'negative')]\n"
     ]
    }
   ],
   "source": [
    "# Step 3a\n",
    "t = [({word: (word in word_tokenize(x[0])) for word in dictionary}, x[1]) for x in train_sample]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4a – the classifier is trained with sample data\n",
    "nbClassifier = nltk.NaiveBayesClassifier.train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "test_data = \"negative,Not Available\"\n",
    "test_data_features = {word.lower(): (word in word_tokenize(test_data.lower())) for word in dictionary}\n",
    "  \n",
    "print (nbClassifier.classify(test_data_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
